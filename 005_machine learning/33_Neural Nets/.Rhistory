install.packages("MASS")
install.packages("neuralnet")
library(MASS)
library(neuralnet)
head(Boston)
str(Boston)
any(is.na(Boston))
data <- Boston
maxs <- apply(data, 2, max)
maxs
mins <- apply(data, 2, min)
mins
help("scale")
scaled.data <- scale(data, center = mins, scale = maxs - mins)
scaled <- as.data.frame(scaled.data)
scaled
head(scaled)
head(Boston)
library(caTools)
split <- sample.split(scaled$medv, SplitRatio = 0.7)
split <- sample.split(scaled$medv, SplitRatio = 0.7)
training.data <- subset(scaled, split == T)
testing.data <- subset(scaled, split == F)
head(training.data)
head(testing.data)
n <- names(train)
n
n <- names(training.data)
n
f <- as.formula(paste("medv ~", paste(n[!n %in% "medv"], collapse = " + ")))
f
nn <- neuralnet(f, data = training.data, hidden = c(5, 3), linear.output = T)
plot(nn)
predicted.nn.values <- compute(nn, test[1:13])
predicted.nn.values <- compute(nn, testing.data[1:13])
str(predicted.nn.values)
true.predictions <- predicted.nn.values$net.result * (max(data$medv) -
min(data$medv)) +
min(data$medv)
# the standardization process done
test.r <- (testing.data$medv) * (max(data$medv) - min(data$medv)) +
min(data$medv)
MSE.nn <- sum((test.r - true.predictions)^2)/nrow(testing.data)
MSE.nn
library(ggplot2)
error.df <- data.frame(test.r, true.predictions)
head(error.df)
library(dply)
library(dplyr)
error.df %>%
ggplot(aes(x = test.r, y = true.predictions)) +
geom_point() +
stat_smooth()
